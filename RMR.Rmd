---
title: "RMR Prediction"
author: "Quirin Manz"
date: "`r Sys.Date()`"
output: html_document
---

# Load Data

## Load Enable Data

```{r, load-enable}
require(readxl)
require(tidytable)
conflicted::conflict_prefer_all('tidytable', quiet = TRUE)
data_foler <- "data"
# load enable data
enable_data <- read_xlsx(file.path(data_foler, "enable_Datensatz_RMR._Erwachsene 1.xlsx"), skip = 2, na=c('NA', 'N/A', ''))
# fix compound values
compounds <- c(
  "acetic acid a", "butyric acid a", "propionic acid a",
  "2-Methylbutyrate a", "hexanoic acid c", "Isobutyrate a",
  "Isovalerate a", "pentanoic acid a",
  "4-Methylvaleric acid a", "Lactic acid a"
)
# for all columns that have a comma in their name, replace commas in the column with a dot
for (column_name in names(enable_data)) {
  if (is.character(enable_data[[column_name]])) {
    enable_data[[column_name]] <-
      sub(",", ".", enable_data[[column_name]], fixed = TRUE)
    if (column_name %in% compounds) {
      # replace "<0" with 0
      enable_data[[column_name]] <-
        ifelse(enable_data[[column_name]] == "<0" |
                 enable_data[[column_name]] == "< 0", 0, enable_data[[column_name]])
    }
  }
}

data_csv <- file.path(data_foler, 'enable_data.tsv')
fwrite(enable_data, file = data_csv)
enable_data <- fread(data_csv, stringsAsFactors = TRUE, na=c('NA', 'N/A', ''))
# remove unnecessary column:
if(all(enable_data[, `Probanden-ID` == Label]))
  invisible(enable_data[, `Probanden-ID` := NULL])
```

## Load Microbiome Data

```{r, load-micro}
# load microbiome mapping
microbiome_mapping <- data.table::setDT(read_xlsx(file.path(data_foler, "mapping_file 1.xlsx")))
microbiome_mapping[, sample_clean := data.table::tstrsplit(".", x = `#SampleID`, fixed = TRUE, keep = 2)]
# check uniqueness
stopifnot(!any(microbiome_mapping[, duplicated(sample_clean)]))

# load microbiome data
microbiome_data <- fread(file.path(data_foler, "tax.summary.all 1.tab"))
stripped_names <- unlist(data.table::tstrsplit(".", x = names(microbiome_data), fixed = TRUE, keep = 2))
# check uniqueness
stopifnot(!any(duplicated(stripped_names)))
# clean names
names(microbiome_data) <- stripped_names
# get taxa names
taxa_names <- microbiome_data[, V1]
# transpose data
microbiome_data <- microbiome_data |> data.table::transpose(keep.names = "sample_clean", make.names = "V1")
# merge microbiome data with mapping
microbiome_data[microbiome_mapping, on=.(sample_clean), c("Label", "Cohort"):=.(Code, as.character(Cohort))]
# merge with enable data
invisible(enable_data[microbiome_data, on=.(Label), (c(taxa_names, "Cohort")) := mget(c(taxa_names, "Cohort"))])
# create field for first letter of label, i.e., categorical Age and Site
invisible(enable_data[, Label_group:=substr(Label, 1, 1)])

```

### Add Alpha Diversity

```{r, alpha-diversity}
# diversity columns
diversity_columns <- c("Shannon.effective", "Simpson.effective")
# load diversity data
diversity_data <- fread('data/Final table.tab', stringsAsFactors=TRUE) |> data.table::setnames(old='V1', new="Label") |> select(Label, all_of(diversity_columns))

invisible(enable_data[diversity_data, on=.(Label), (c(diversity_columns)) := mget(diversity_columns)])
```

## Set Variable Groups

```{r, load-column-groups}
# groups for taxa
taxa_group <-
  c(
    k = 'kingdom',
    p = 'phylum',
    c = 'class',
    o = 'order',
    f = 'family',
    g = 'genus'
  )[data.table::tstrsplit(taxa_names,
                          split = '__',
                          keep = 1,
                          fixed = TRUE)[[1]]]
# match the columns to certain groups
column_groups <- rbind(data.table::data.table(column = 'Label_group', group = "General information"),
                       fread(file.path(data_foler, 'column_groups.tsv')),
                       data.table::data.table(column = taxa_names, group = paste("microbiome", taxa_group)),
                       data.table::data.table(column = diversity_columns, group = paste("microbiome diversity")))
column_groups[, group:=as.factor(group)]

# set general response variable
response_variable <- "RMR.KJ"
# define grouping column
grouping_column <- "Label_group"
# get other labelling columns
other_labelling_columns <- c("Label", "Site", "Cohort", "Datum_V1")
# set the predictor of the established model
basic_predictors <- c("SEX", "Alter, Jahre", "FETTMASSE_SECA, kg", "FFM_SECA,kg")
# define microbial predictors (family level)
microbiome_predictors <- column_groups[group == 'microbiome family', column]
# # other microbial columns
# other_microbial_columns <- setdiff(taxa_names, microbial_predictors)
# define the general predictors
general_predictors <- setdiff(names(enable_data), c(response_variable, grouping_column, other_labelling_columns, taxa_names))
```

# Build Models

## Split and Check Data

```{r, prepare-models}
suppressPackageStartupMessages(library(tidymodels))
tidymodels_prefer()
ggplot2::theme_set(ggplot2::theme_bw() + theme(strip.background = element_rect(fill = "white")))

# number of NA responses
message(paste("Number of NAs in response: ", enable_data |> filter(is.na(`RMR.KJ`)) |> nrow()))
enable_data <- enable_data |> subset(!is.na(`RMR.KJ`))

# set seed for reproducibility
set.seed(1)
# split the data by Site to have a test sets
enable_split <- group_initial_split(enable_data, group = "Site")
test_data <- enable_split |> testing()
train_data <- enable_split |> training()

# ensure that Site == "freising" in the whole train_data
stopifnot(all(train_data$Site == 'freising'))

# Number of samples that have at least one NA value
message(paste("Number of NAs in any variable: ", train_data |>
  filter_all(any_vars(is.na(.))) |>
  nrow()))

# # filter such that all samples have no NA values
# full_train_data <- train_data |>
#   filter_all(all_vars(!is.na(.)))

# set number of folds and also register parallel processing
nfolds <- 5
nrepeats <- 10

set.seed(1102)
repeated_cv_split <- rsample::vfold_cv(train_data, v = nfolds, repeats = nrepeats)
grouped_split <- rsample::group_vfold_cv(train_data, all_of(grouping_column), v = 3)
```

## Configure Models

```{r, configure-models}
# create recipes
general_recipe <-
  recipe(train_data) |>
  update_role(all_of(general_predictors), new_role = "predictor") |>
  update_role(all_of(response_variable), new_role = "outcome") |>
  update_role(all_of(other_labelling_columns), new_role = "labels") |>
  update_role(all_of(grouping_column), new_role = "splitting indicator") |>
  update_role(all_of(taxa_names), new_role = "microbiome") |>
  update_role(all_of(microbiome_predictors), new_role = "predictor") |>
  step_impute_mean(all_numeric_predictors()) |>
  step_zv(all_predictors())

orig_scale_recipe <- general_recipe  |>
  step_dummy(all_nominal_predictors()) 

normalized_recipe <- general_recipe  |>
  step_normalize(all_numeric_predictors()) |> 
  step_dummy(all_nominal_predictors())

# basic_recipe <- general_recipe |>
#   update_role(all_of(general_predictors), new_role = "old_predictor") |>
#   update_role(all_of(basic_predictors), new_role = "predictor")

# meanImpute_recipe <- general_recipe |>
#   update_role(all_of(microbiome_predictors), new_role = "predictor")

# interaction_recipe <- meanImpute_recipe |>
#   step_poly(all_numeric_predictors(), degree = 2) |>
#   step_interact(~ all_predictors():all_predictors())
  
# recipe list
recipe_list <- list(# basic = basic_recipe,
                    # general = general_recipe,
                    # interactions = interaction_recipe,
                    normalized = normalized_recipe,
                    origScale = orig_scale_recipe)

main_metric <- "rsq"
my_metrics <- metric_set(rmse, ccc, rsq, rsq_trad, mae)

# linear model
lm_model <- 
  linear_reg() |> 
  set_engine("lm")

# elastic net model
elnet_model <-
  linear_reg(penalty = tune(), mixture = tune()) |>
  set_engine("glmnet")

# lasso model
lasso_model <- 
  linear_reg(penalty = tune(), mixture = 1) |> 
  set_engine("glmnet", standardize = TRUE)

# random forest
rf_model <-
  rand_forest(trees = tune(), min_n = tune(), mtry = tune()) |> 
  set_engine("ranger", importance = 'permutation') |> 
  set_mode("regression")

# neural network
nnet_model <- 
   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) |> 
   set_engine("nnet", MaxNWts = 2600) |> 
   set_mode("regression")

# model list
model_list <- list(linear = lm_model,
                   # elnet = elnet_model,
                   lasso = lasso_model,
                   RF = rf_model,
                   nnet = nnet_model)

# set the same parameters for all penalties
penalty_range <- penalty(range=c(-10, 3))

# set the parameters for the elnet
elnet_params <-
  elnet_model |>
  extract_parameter_set_dials() |>
  update(penalty = penalty_range)

# set the parameters for the lasso
lasso_params <-
  lasso_model |>
  extract_parameter_set_dials() |>
  update(penalty = penalty_range)

# set the parameters for the RF
rf_params <-
  rf_model |>
  extract_parameter_set_dials() 

# set the parameters for the NN
nnet_params <- 
   nnet_model |> 
   extract_parameter_set_dials() |> 
   update(hidden_units = hidden_units(c(1, 27))) |>
   update(penalty = penalty_range)

params_list <- list(elnet = elnet_params,
                   lasso = lasso_params,
                   RF = rf_params,
                   nnet = nnet_params)

```

## Configure Workflows

```{r, add-params}
# set the workflows
workflows <- workflow_set(
      preproc = c(recipe_list['normalized'],
                  recipe_list['origScale'],
                  recipe_list['origScale'], 
                  recipe_list['origScale'], 
                  recipe_list['normalized']), 
      models = c(model_list['lasso'],
                 model_list),
      cross = FALSE)

workflows <- workflows |>
    option_add(grid = 100)
 
# iterate over the RF wflow_ids and generate the mtry parameter dynamically
for (this_wflow_id in workflows$wflow_id){
  model_name <- data.table::tstrsplit(this_wflow_id, '_', fixed = TRUE, keep = 2)[[1]]
  # set the parameters for the RF in question
  params <- params_list[[model_name]]
  if (model_name == "RF"){
    params <- params |> 
    update(mtry = mtry(c(
      1, sum(recipe_list[[sub("_.*", "", this_wflow_id)]]$var_info$role == "predictor")
    ))) }
  workflows <- workflows |> 
    option_add(param_info = params, id = this_wflow_id)
  # if (!is.null(params))
  # workflows <- workflows |>
  #   option_add(grid = 100)#params |>
                 # grid_space_filling(type = "uniform", size = 30), id = this_wflow_id)
  
}

ctrl_parallel_over <- "everything"
# define the grid
grid_ctrl <-
   control_grid(
      save_pred = TRUE,
      save_workflow = TRUE,
      parallel_over = ctrl_parallel_over
   )

bayes_ctrl <-
    control_bayes(
      save_pred = TRUE,
      save_workflow = TRUE,
      parallel_over = ctrl_parallel_over
    )
```

## Train Models

```{r, train-models}
# train or load the models, depending on availibility
# if (! file.exists("cv_results.rds")) {
#   # train the models
require(doMC)
if (ctrl_parallel_over == 'everything') {
  doMC::registerDoMC(cores = nfolds * nrepeats)
} else {
  doMC::registerDoMC(cores = nrepeats)
}
  # All operating systems
  # require(doParallel)
  # 
  # # Create a cluster object and then register: 
  # cl <- makePSOCKcluster(nrepeats)
  # registerDoParallel(cl)
  
  # grid_cv_result <- ifelse(file.exists("grid_cv_results.rds"), readRDS("grid_cv_results.rds"), list)
split_list <- list(grouped = grouped_split, repeated = repeated_cv_split)
cv_results <- lapply(names(split_list), function(this_split_name) {
  print(this_split_name)
  this_split <- split_list[[this_split_name]]
  grid_result_file <-
    file.path('fits', paste("grid", this_split_name, "results.rds", sep = "_"))
  if (file.exists(grid_result_file)) {
    print("loading grid results")
    grid_results <- readRDS(grid_result_file)
  } else {
    print("creating grid results")
    grid_results <- workflows |>
      workflow_map(
        fn = "tune_grid",
        seed = 1503,
        resamples = this_split,
        control = grid_ctrl,
        verbose = TRUE,
        metrics = my_metrics
      )
    saveRDS(grid_results, grid_result_file)
  }
  return(grid_results)
  bayes_result_file <-
    file.path('fits', paste("bayes", this_split_name, "results.rds", sep = "_"))
  if (file.exists(bayes_result_file)) {
    print("loading bayes results")
    bayes_results <- readRDS(bayes_result_file)
  } else {
    print("creating bayes results")
    wf_with_initial <- workflows |>
      option_remove(grid)
    for (this_wflow_id in workflows$wflow_id) {
      wf_with_initial <- wf_with_initial |>
        option_add(
          id = this_wflow_id,
          initial = grid_results |> extract_workflow_set_result(id = this_wflow_id)
        )
    }
    bayes_results <- wf_with_initial |>
      workflow_map(
        fn = "tune_bayes",
        seed = 1503,
        resamples = this_split,
        iter = 50,
        control = bayes_ctrl,
        verbose = TRUE,
        metrics = my_metrics
      )
    saveRDS(bayes_results, bayes_result_file)
  }
  return(bayes_results)
})
  # stopCluster(cl)
  
  names(cv_results) <- names(split_list)
#   saveRDS(cv_results, "cv_results.rds")
# } else {
#   # load the models
#   cv_results <- readRDS("cv_results.rds")
# }
```

## Evaluate Models and Select Best

```{r, plot-results-select-best, fig.width=10, fig.height=6}
wflow_ids <- workflows$wflow_id
wflow_ids_wo_linear <- wflow_ids[!endsWith(wflow_ids, "_linear")]
  
best_models_per_split <- lapply(names(cv_results), function(this_split_name){
  this_result <- cv_results[[this_split_name]]
  print(autoplot(this_result, type="wflow_id") + labs(title = this_split_name))
  # print(autoplot(
  #    this_result,
  #    rank_metric = main_metric,
  #    select_best = TRUE,
  #    type="wflow_id"    
  # ) + labs(title = this_split_name))
  
  final_models <- sapply(wflow_ids_wo_linear, function(this_wflow_id) {
    wflow_results <- this_result |> 
      extract_workflow_set_result(this_wflow_id)
    print(autoplot(wflow_results) + labs(title=paste(this_split_name, this_wflow_id)))
    # print(autoplot(wflow_results, type = 'performance') + labs(title = paste(this_split_name, this_wflow_id)))
    specs <- workflows |> extract_spec_parsnip(this_wflow_id)
    tuning_params <- specs |> extract_parameter_set_dials() |> pull(name)
    if (inherits(specs, "linear_reg")) {
      if (all(c("penalty", "mixture") %in% tuning_params))
        best_model <- wflow_results |> select_by_one_std_err(metric = main_metric, desc(penalty), mixture)
      else if ("penalty" %in% tuning_params)
        best_model <- wflow_results |> select_by_one_std_err(metric = main_metric, desc(penalty))
      else if ("mixture" %in% tuning_params)
        best_model <- wflow_results |> select_by_one_std_err(metric = main_metric, mixture)
    } else if (inherits(specs, "rand_forest")) {
      best_model <- wflow_results |> select_by_one_std_err(metric = main_metric, trees, mtry, desc(min_n))
    } else if (inherits(specs, "mlp")) {
      best_model <- wflow_results |> select_by_one_std_err(metric = main_metric, epochs, hidden_units, desc(penalty))
    }
    
    # list(one_std_err_results = best_model, 
    #      fit = this_result |>
    #        extract_workflow(this_wflow_id) |>
    #        finalize_workflow(best_model) |>
    #        last_fit(split = enable_split, metrics=my_metrics))
    best_model
    
  }, simplify = FALSE)

  one_std_err_results <-
    data.table::rbindlist(
      final_models,
      idcol = 'wflow_id',
      fill = TRUE
    ) |>
    select(wflow_id, .config)
  best_results <- this_result |> 
    rank_results(rank_metric = main_metric, select_best = TRUE) |>
    select(wflow_id, .config) |>
    unique()
  results_to_keep <- rbind(one_std_err_results, best_results)
  
  cv_result_dt <- this_result |> rank_results(rank_metric = main_metric) |> semi_join(results_to_keep)
  cv_result_dt[, rank := factor(rank, levels = sort(unique(rank)))]
  
  print(ggplot(cv_result_dt, aes(x = rank, y = mean, color = wflow_id)) +
    geom_point() +
    geom_errorbar(aes(ymin = mean - std_err, ymax = mean + std_err), width = .5) +
    facet_wrap(~.metric, scales = 'free') + labs(title = this_split_name))
  
  final_fits <- sapply(names(final_models), function(this_wflow_id)
    this_result |>
           extract_workflow(this_wflow_id) |>
           finalize_workflow(final_models[[this_wflow_id]]) |>
           last_fit(split = enable_split, metrics=my_metrics),
    simplify = FALSE)
  
  linear_models <- sapply(wflow_ids[!wflow_ids %in% wflow_ids_wo_linear], function(this_wflow_id){
    this_recipe_name <- sub(pattern = '_.*$', replacement = '', this_wflow_id)
    workflow() |> 
      add_recipe(recipe_list[[this_recipe_name]]) |>
      add_model(lm_model) |> 
      last_fit(split = enable_split, metrics = my_metrics)
  }, simplify = FALSE)
  c(final_fits, linear_models)
})
names(best_models_per_split) <- names(cv_results)
```


### Evaluate LASSO Feature Robustness

```{r, lasso-robustness, fig.width=8, fig.height=8}
library(glmnet)

# prepare x and y 
prepped_training_data <- orig_scale_recipe |> step_select(c(all_predictors(), all_outcomes())) |> prep() |> bake(NULL)
x <- prepped_training_data |> select(-any_of(response_variable)) |> as.matrix()
y <- prepped_training_data |> pull(response_variable)

# get the repeats from our repeated split
repeat_ids <- repeated_cv_split$id |> unique()

# lasso runs per repeat
cvfits <- 
  lapply(repeat_ids, function(repeat_id) {
  # Filter the splits for the specified repeat
  repeat_splits <- repeated_cv_split |> subset(id == repeat_id)
  
  # Initialize a fold ID vector (length = number of rows in the data)
  fold_ids <- integer(train_data |> nrow())
  
  # Assign fold numbers to each observation based on assessment sets
  for (i in seq_along(repeat_splits$splits)) {
    fold <- repeat_splits$splits[[i]]
    assessment_indices <- tidy(fold) |> subset(Data == "Assessment") |> pull(Row)
    fold_ids[assessment_indices] <- i  # Assign fold number `i` to assessment indices
  }
  stopifnot(all(fold_ids>0))
  
  lasso <-
    cv.glmnet(
      x = x,
      y = y,
      alpha = 1,
      family = "gaussian",
      foldid = fold_ids,
      standardize = TRUE
    )
  
  lasso
}) 
names(cvfits) <- repeat_ids

nonzero_coefs <- lapply(cvfits, function(cvfit) {
  # get the nonzero coefficients
  coefs <- coef(cvfit, s = "lambda.1se")
  nonzero_coefs <- coefs[coefs[, 1] != 0, ]
  sort(nonzero_coefs, decreasing = TRUE)
  names(nonzero_coefs)
  })
names(nonzero_coefs) <- repeat_ids

feature_colors <- c(
  "FFM_SECA,kg" = "#009999",          # Teal (greenish for FFM_SECA)
  "GEWICHt_SECA, kg" = "#B2DF8A",    # Light Green (for GEWICHt_SECA)
  "mean_temp" = "#171723",           # Black (for mean_temp)
  "GFRCKDE, mg/min" = "#ff6db6",     # Pink (blood measure GFRCKDE)
  "FT3, pg/ml" = "#b66dff",          # Purple (blood measure FT3)
  "MCHC, g/dl" = "#490092",          # Dark Purple (blood measure MCHC)
  "unexplained" = "#db6d00",         # Orange (for unexplained)
  "individual variation" = "#FDB462" # Light Orange (for individual variation)
)

transposed_df <- stack(nonzero_coefs)
# remove intercept from values
transposed_df <- data.table::setDT(transposed_df) |> subset(values != "(Intercept)")
ggplot(transposed_df, aes(x = reorder(values, ind, function(x) -length(x)), fill = values)) +
  geom_bar() +
  scale_fill_manual(values = feature_colors) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = 'none') +
  labs(title = "LASSO Feature Robustness", x = "Feature", y = "Count")
```

### Evaluate Best Lasso Coefficients

```{r, tidy-lasso-coefs}
# LASSO can be used for feature selection only, so now we will build a more complex model with the selected variables from LASSO
normalized_lasso_coefs <- best_models_per_split$repeated$normalized_lasso |> extract_fit_parsnip() |> tidy() |> subset(estimate != 0) |> mutate(abs_estimate = abs(estimate)) |> arrange(desc(abs_estimate)) |> select(-abs_estimate)
print(normalized_lasso_coefs)
normalized_lasso_coefs <- normalized_lasso_coefs |> subset(term != '(Intercept)')
normalized_lasso_coefs[, term:=factor(term, levels=term)]

# Function to calculate luminance
calculate_luminance <- function(hex_color) {
  rgb <- col2rgb(hex_color) / 255
  # Apply relative luminance formula
  luminance <- 0.2126 * rgb[1, ] + 0.7152 * rgb[2, ] + 0.0722 * rgb[3, ]
  return(luminance)
}

# Decide text color (black or white) based on luminance threshold
text_colors <- sapply(feature_colors, function(color) {
  if (calculate_luminance(color) > 0.5) {
    "black"  # Light background -> Black text
  } else {
    "white"  # Dark background -> White text
  }
})

ggplot(normalized_lasso_coefs, aes(x = estimate, y = reorder(term, abs(estimate)), fill = term)) +
    geom_col() +
    scale_fill_manual(values = feature_colors) +
    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) + 
    labs(x = "LASSO Coefficient on Standardized Features", y = NULL, fill = NULL)
```


```{r, tidy-lasso-coefs-origScale}
best_models_per_split$repeated$normalized_lasso <- NULL
selected_coefs <- best_models_per_split$repeated$origScale_lasso |> extract_fit_parsnip() |> tidy() |> subset(estimate != 0) |> mutate(abs_estimate = abs(estimate)) |> arrange(desc(abs_estimate)) |> select(-abs_estimate)
print(selected_coefs)
```


### Build More Complex Models

```{r, complex-models}
selected_features <- selected_coefs |> subset(term != '(Intercept)') |> pull(term)

# now let's make another recipe using only those features
selected_recipe <- orig_scale_recipe |>
  update_role(all_of(general_predictors), new_role = "old_predictor") |>
  update_role(all_of(microbiome_predictors), new_role = "old_predictor") |>
  update_role(all_of(selected_features), new_role = "predictor") |>
  update_role_requirements(role = "old_predictor", bake = FALSE) |>
  update_role_requirements(role = "labels", bake = FALSE) |>
  update_role_requirements(role = "microbiome", bake = FALSE) |>
  update_role_requirements(role = "splitting indicator", bake = FALSE)

quadratic_recipe <- selected_recipe |>
  step_poly(all_numeric_predictors(), degree = 2) 

interaction_recipe <- selected_recipe |>
  step_interact(~ all_predictors():all_predictors())

new_recipes <- list(selected = selected_recipe, 
                     quadratic = quadratic_recipe, 
                     interaction = interaction_recipe)

recipe_list <- c(recipe_list, new_recipes)

new_models <- sapply(new_recipes, 
       function(this_recipe){
         workflow() |> 
           add_recipe(this_recipe) |>
           add_model(lm_model) |>
           last_fit(split = enable_split, metrics = my_metrics)
}, simplify = FALSE)
names(new_models) <- paste(names(new_models), 'linear', sep = "_")
best_models_per_split$repeated <- c(best_models_per_split$repeated, new_models)
```

#### Evaluate Models with Selected Features

```{r, selected-models, fig.width=11, fig.height=7}
require(ggrepel)
selected_lm_fits <- sapply(new_models,
       function(model) {
         lm_fit <- model |> extract_fit_engine()
         coef_mat <- lm_fit |> summary() |> coefficients()
         # coef_mat[coef_mat[, 'Pr(>|t|)'] < 0.05, , drop = FALSE] |> print()
         lm_fit
       }, simplify = FALSE)

feature_imps <- c("lmg", "pmvd")
linear_imp <- relaimpo::calc.relimp(selected_lm_fits$selected_linear, type = feature_imps)
expl_variance <- data.table::setDT(enframe(c(linear_imp$pmvd, `individual variation` = 0.043, unexplained = 0), 'Feature', 'Explained Variance'))
expl_variance[Feature == 'unexplained', `Explained Variance` := 1 - sum(expl_variance$`Explained Variance`)]
expl_variance[, Feature:=factor(Feature, levels=c(names(sort(linear_imp$pmvd, decreasing = TRUE)), 'unexplained', 'individual variation'))]
data.table::setkey(expl_variance, Feature)
expl_variance[, cum_var := cumsum(`Explained Variance`)]
expl_variance[, x_space := cum_var - `Explained Variance`/2]

ggplot(expl_variance, aes(x = `Explained Variance`, y = 'Feature', fill = reorder(Feature, -x_space))) + 
    geom_col(position = 'fill') + 
    scale_fill_manual(values = feature_colors, guide = guide_legend(reverse = TRUE, nrow = 1)) + 
    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), legend.position = 'top') + 
    ggrepel::geom_label_repel(aes(label = round(`Explained Variance`, 3),
                                  x = x_space,
                                  y = 1.45),
                              max.overlaps = 10,
                              min.segment.length = 0,
                              force = 10,
                              show.legend = FALSE,
                              color = text_colors,
                              segment.color = 'black') + 
    labs(y = NULL, fill = NULL)

ggplot(
  enframe((
    best_models_per_split$repeated$origScale_RF |> extract_fit_engine()
  )$variable.importance,
  'feature',
  'var_imp'
  ) |> arrange(desc(var_imp)) |> slice_head(n = 20),
  aes(x = var_imp, y = reorder(feature, var_imp))
) + geom_col()
```


### Current Methods in Literature

```{r, current-methods}
# Conversion factor kcal to kilojoule
conversion_factor <- 4.184

HarrisBenedict <- function(weight, height, age, sex_female){
  ifelse(sex_female, 
         655.1 + 9.6*weight + 1.8*height - 4.7*age,
         66.47 + 13.7*weight + 5*height - 6.8*age) * conversion_factor
}

Kleiber <- function(weight){
  283 * weight^0.75
}

WHO <- function(weight, age, sex_female) {
  
  # Initialize RMR vector
  RMR <- numeric(length(weight))
  
  # Define reusable age filters
  age_filter <- list(
    age_3_10 = age <= 18,
    age_10_30 = age >= 18 & age <= 30,
    age_30_60 = age > 30 & age <= 60,
    age_60_plus = age > 60
  )
  
  # Calculate RMR for each age group using `ifelse` conditioned on `sex_female`
  RMR[age_filter$age_3_10] <- ifelse(sex_female[age_filter$age_3_10],
                                     (22.5 * weight[age_filter$age_3_10] + 499),
                                     (22.7 * weight[age_filter$age_3_10] + 495))
  
  RMR[age_filter$age_10_30] <- ifelse(sex_female[age_filter$age_10_30],
                                      (14.7 * weight[age_filter$age_10_30] + 496),
                                      (15.3 * weight[age_filter$age_10_30] + 679))
  
  RMR[age_filter$age_30_60] <- ifelse(sex_female[age_filter$age_30_60],
                                      (8.7 * weight[age_filter$age_30_60] + 829),
                                      (11.6 * weight[age_filter$age_30_60] + 879))
  
  RMR[age_filter$age_60_plus] <- ifelse(sex_female[age_filter$age_60_plus],
                                        (10.5 * weight[age_filter$age_60_plus] + 596),
                                        (13.5 * weight[age_filter$age_60_plus] + 487))
  
  return(RMR*conversion_factor)
}

```

## Compute Training and Testing Errors

```{r, helper-functions}
predict_data_fits <- function(fits, recipe_list, truth, new_data = NULL) {
  data.table::rbindlist(
    sapply(names(fits), function(this_wflow_id) {
      last_fit <- fits[[this_wflow_id]]
      this_recipe_name <- sub(pattern = '_.*$', replacement = '', this_wflow_id)
      this_recipe <- recipe_list[[this_recipe_name]]
      prepped_data <- this_recipe |> step_select(all_of(c(all_predictors(), all_outcomes()))) |> prep() |> bake(new_data = new_data)
      last_fit |> extract_fit_parsnip() |> predict(new_data = prepped_data) |> mutate(truth = truth)
    }, simplify = FALSE),
    idcol = 'model'
  ) |> rename(estimate = .pred)
}

predict_data_established <- function(new_data, truth){
  data.table::rbindlist(list(
    data.table::data.table(model = 'Harris-Benedict', 
                           estimate = HarrisBenedict(weight = new_data$`GEWICHt_SECA, kg`,
                                                     height = new_data$`GROESSE, cm`,
                                                     age = new_data$`Alter, Jahre`,
                                                     new_data$SEX == 'weiblich'),
                           truth = truth),
    data.table::data.table(model = 'Kleiber', 
                           estimate = Kleiber(weight = new_data$`GEWICHt_SECA, kg`),
                           truth = truth),
    data.table::data.table(model = 'WHO', 
                           estimate = WHO(weight = new_data$`GEWICHt_SECA, kg`, 
                                          age = new_data$`Alter, Jahre`,
                                          sex_female = new_data$SEX == 'weiblich'),
                           truth = truth)
    )
  )
}

compute_my_metrics <- function(preds, my_metrics){
  metric_dt <- preds[, my_metrics(.SD, truth = truth, estimate = estimate), by=model]
  metric_dt <- data.table::dcast(metric_dt, model ~ .metric, value.var = '.estimate')
  metric_names <- names(metric_dt)[names(metric_dt) != 'model']
  metric_dt[, metrics_string := do.call(
      paste, 
      c(Map(function(name, value) paste(name, round(value, 2), sep = ": "), metric_names, mget(metric_names)), sep = "\n")
  )]
  metric_dt
}

plot_preds <- function(preds, metric_dt, main_metric, focus_observed = FALSE){
  p <- ggplot(preds, aes(x = truth, y = estimate)) +
    geom_abline(color = "gray50", lty = 2) + 
    geom_point(alpha = 0.5) + 
    facet_wrap(~factor(model, levels = metric_dt[order(get(main_metric)), model]), nrow = 2) +
    labs(title = 'Errors', x = 'Observed', y = 'Predicted') +
    geom_label(data = metric_dt, aes(x = Inf, y = -Inf, label = metrics_string), 
               hjust = 1.1, vjust = -0.1, inherit.aes = FALSE, size = 3)
  if (focus_observed) {
    p <- p +
      coord_obs_pred(xlim=c(min(preds$truth), max(preds$truth)),
                     ylim=c(min(preds$truth), max(preds$truth)))
          
  } else {
    p <- p +
      coord_obs_pred()
  }
  p
}

plot_bland_altman <- function(preds, metric_dt, main_metric) {
  preds[, mean_measurement:=(truth + estimate)/2]
  preds[, difference:= truth - estimate]
  preds[, mean_difference:=mean(difference), by=model]
  preds[, lower_difference:= mean_difference - sd(difference)*1.96, by=model]
  preds[, upper_difference:= mean_difference + sd(difference)*1.96, by=model]
  
  ggplot(preds, aes(x = mean_measurement, y = difference)) +
    geom_hline(aes(yintercept = mean_difference)) +
    geom_hline(aes(yintercept = lower_difference), linetype = 'dashed') +
    geom_hline(aes(yintercept = upper_difference), linetype = 'dashed') +
    geom_point(alpha = 0.5) + 
    facet_wrap(~factor(model, levels = metric_dt[order(get(main_metric)), model]), nrow = 2) +
    labs(title = 'Bland-Altman', x = 'Mean Measurement', y = 'Difference')
}


```


### Freising/Training Errors

```{r, training-errors, fig.width=12, fig.height=6}
interesting_models <- c("Harris-Benedict", "Kleiber", "WHO", "origScale_lasso")

freising_preds <- predict_data_fits(fits = best_models_per_split$repeated, 
                                    recipe_list = recipe_list, 
                                    truth = train_data$RMR.KJ)
  
freising_preds <- rbind(
  freising_preds,
  predict_data_established(train_data, train_data$RMR.KJ)
)

freising_metrics <- compute_my_metrics(freising_preds, my_metrics)

plot_preds(freising_preds, freising_metrics, main_metric = main_metric)

plot_bland_altman(freising_preds, freising_metrics, main_metric)
```

### Nürnberg/Testing Errors
```{r, nuremberg-testing-errors, fig.width=12, fig.height=6}
nuremberg_preds <-
  data.table::rbindlist(
    sapply(
      best_models_per_split$repeated,
      collect_predictions,
      simplify = FALSE
    ),
    idcol = 'model'
  ) |> rename(truth = RMR.KJ, estimate = .pred) |> select(model, estimate, truth) 

nuremberg_preds <- rbind(
  nuremberg_preds,
  predict_data_established(test_data, test_data$RMR.KJ)
)

nuremberg_metrics <- compute_my_metrics(nuremberg_preds, my_metrics)

plot_preds(nuremberg_preds, nuremberg_metrics, main_metric = main_metric)

plot_preds(nuremberg_preds, nuremberg_metrics, main_metric = main_metric, focus_observed = TRUE)
plot_bland_altman(nuremberg_preds, nuremberg_metrics, main_metric)

plot_preds(nuremberg_preds[model %in% interesting_models], nuremberg_metrics[model %in% interesting_models], main_metric = main_metric)
```


```{r, nuremberg-testing-ba, fig.width=12, fig.height=4}
nuremberg_ba <- plot_bland_altman(nuremberg_preds[model %in% interesting_models], nuremberg_metrics, main_metric)
nuremberg_ba[["facet"]][["params"]][["nrow"]] <- 1
nuremberg_ba
```


### München/Testing Errors
```{r, munich-testing-errors, fig.width=12, fig.height=6}
munich_data <- data.table::setDT(readxl::read_xlsx('data/RMR_munich.xlsx'))
munich_data_extension <- data.table::setDT(readxl::read_xlsx('data/Datenbank_GU_Daten an Frau Keppner_22.02.2019.xlsx'))
# munich_data[, `GEWICHt_SECA, kg` := fm + ffm]
munich_data[munich_data_extension, on=c(Label='ID'), c('GROESSE, cm', 'GEWICHt_SECA, kg', 'SEX') :=.(Größe, Gewicht, Geschl)]
munich_data[, `FFM_SECA,kg` := ffm]
munich_data[, `Alter, Jahre` := age]
# munich_data[, SEX := paste0(SEX, 'ich')]
munich_data[, SEX := ifelse(sex == 2, yes = 'weiblich', no = 'männlich')]
munich_data[, SEX := factor(SEX, levels = levels(enable_data$SEX))]
munich_data[, Site:='munich']

munich_data[, (names(enable_data)[!names(enable_data) %in% names(munich_data)]) := NA]

munich_preds <- predict_data_fits(fits = best_models_per_split$repeated,
                                  recipe_list = recipe_list, 
                                  truth = munich_data$RMR.KJ,
                                  new_data = munich_data)

munich_preds <- rbind(
  munich_preds,
  predict_data_established(munich_data, munich_data$RMR.KJ)
)

munich_metrics <- compute_my_metrics(munich_preds, my_metrics)

plot_preds(munich_preds, munich_metrics, main_metric = main_metric)

plot_preds(munich_preds, munich_metrics, main_metric = main_metric, focus_observed = TRUE)
plot_bland_altman(munich_preds, munich_metrics, main_metric)

plot_preds(munich_preds[model %in% interesting_models], munich_metrics[model %in% interesting_models], main_metric = main_metric)
```


```{r, munich-testing-ba, fig.width=12, fig.height=4}
munich_ba <- plot_bland_altman(munich_preds[model %in% interesting_models], munich_metrics[model %in% interesting_models], main_metric)
munich_ba[["facet"]][["params"]][["nrow"]] <- 1
munich_ba
```

```{r}
all_data <- rbind(enable_data[, .(Site, mean_temp, RMR.KJ, SEX, `Alter, Jahre`)], munich_data[, .(Site, mean_temp, RMR.KJ, SEX, `Alter, Jahre`)])
ggplot(rbind(enable_data[, .(Site, mean_temp, RMR.KJ)], munich_data[, .(Site, mean_temp, RMR.KJ)]), aes(x = mean_temp, y = RMR.KJ, color = Site)) + geom_point(alpha=.5) + geom_smooth(method = 'lm', se = FALSE)
```

